{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2da05122"
      },
      "source": [
        "\n",
        "# 🎯 Projeto de Transcrição e Análise de Sentimentos\n",
        "\n",
        "Este projeto utiliza **Python e NLP** para transcrever áudios e analisar sentimentos de interações com clientes.  \n",
        "A análise é baseada no **Net Promoter Score (NPS)** para entender melhor a satisfação dos clientes.\n",
        "\n",
        "## 🔍 Estrutura do Código:\n",
        "1. **Importação das bibliotecas**\n",
        "2. **Carregamento e limpeza dos dados**\n",
        "3. **Processamento e análise**\n",
        "4. **Visualização dos resultados**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrwYS8Uylr2w",
        "outputId": "d8386725-8590-402e-ff95-3766d596202c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803406 sha256=b1d0e2452a663cfb19659f9f483466d7f3645577e8d12b9d4b41d648ddfde4c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=af4064de3e9bf3447b1394d0feb361127e0c99071db7cf7fc0c06b4873a83b9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n",
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Downloading speechrecognition-3.14.2-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.2\n",
            "Requirement already satisfied: whisper in /usr/local/lib/python3.11/dist-packages (1.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n",
        "!pip install whisper\n",
        "!pip install SpeechRecognition\n",
        "!pip install --upgrade whisper\n",
        "!pip install --upgrade librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "QwonTjiRl5QR",
        "outputId": "4cc23656-cf2c-4e2a-b33c-f13b2ba0d9b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7c2269d0-11c6-4c52-b3de-f52ee2be08e4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7c2269d0-11c6-4c52-b3de-f52ee2be08e4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2874774.wav to 2874774.wav\n",
            "Saving 2874830.wav to 2874830.wav\n",
            "Saving 2961972.wav to 2961972.wav\n",
            "Saving 2962046.wav to 2962046.wav\n",
            "Saving 2962074.wav to 2962074.wav\n",
            "Arquivos de áudio uploadados:\n",
            "1. 2874774.wav\n",
            "2. 2874830.wav\n",
            "3. 2961972.wav\n",
            "4. 2962046.wav\n",
            "5. 2962074.wav\n",
            "Transcrição em progresso para: 2874774.wav...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:09<00:00, 51.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcrição concluída para: 2874774.wav!\n",
            "Transcrição salva em: 2874774.wav_transcricao.txt\n",
            "Transcrição em progresso para: 2874830.wav...\n",
            "Transcrição concluída para: 2874830.wav!\n",
            "Transcrição salva em: 2874830.wav_transcricao.txt\n",
            "Transcrição em progresso para: 2961972.wav...\n",
            "Transcrição concluída para: 2961972.wav!\n",
            "Transcrição salva em: 2961972.wav_transcricao.txt\n",
            "Transcrição em progresso para: 2962046.wav...\n",
            "Transcrição concluída para: 2962046.wav!\n",
            "Transcrição salva em: 2962046.wav_transcricao.txt\n",
            "Transcrição em progresso para: 2962074.wav...\n",
            "Transcrição concluída para: 2962074.wav!\n",
            "Transcrição salva em: 2962074.wav_transcricao.txt\n",
            "CSV gerado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "#importando as bibliotecas\n",
        "import whisper\n",
        "import re\n",
        "from google.colab import files\n",
        "import os\n",
        "import markdown\n",
        "import warnings\n",
        "import pickle\n",
        "import time\n",
        "import concurrent.futures\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Criar diretório para salvar transcrições\n",
        "os.makedirs('transcricoes', exist_ok=True)\n",
        "\n",
        "# Criar diretório para salvar cache\n",
        "os.makedirs('cache', exist_ok=True)\n",
        "\n",
        "# Módulo de transcrição e análise de áudio\n",
        "def transcrever_e_analisar_audio(arquivo_de_audio):\n",
        "    try:\n",
        "        print(f\"Transcrição em progresso para: {arquivo_de_audio}...\")\n",
        "        modelo = whisper.load_model(\"small\")\n",
        "        resultado = modelo.transcribe(arquivo_de_audio)\n",
        "        print(f\"Transcrição concluída para: {arquivo_de_audio}!\")\n",
        "\n",
        "        texto = resultado[\"text\"]\n",
        "        duracao = resultado[\"segments\"][-1][\"end\"]  # Duração do áudio em segundos\n",
        "\n",
        "        # Melhorar a formatação\n",
        "        texto = markdown.markdown(texto)\n",
        "\n",
        "        # Remover ruídos\n",
        "        texto = re.sub(r\"Tá|Ah\", \"\", texto)\n",
        "\n",
        "        # Calcular total de palavras\n",
        "        total_palavras = len(re.findall(r'\\w+', texto))\n",
        "\n",
        "        return texto, duracao, total_palavras\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao transcrever áudio: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Função para salvar a transcrição em um arquivo\n",
        "def salvar_transcricao(texto, nome_arquivo):\n",
        "    with open(f'transcricoes/{nome_arquivo}', 'w', encoding='utf-8') as f:\n",
        "        f.write(texto)\n",
        "\n",
        "# Função para carregar cache\n",
        "def carregar_cache():\n",
        "    try:\n",
        "        with open('cache/cache.pkl', 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return {}\n",
        "\n",
        "# Função para salvar cache\n",
        "def salvar_cache(cache):\n",
        "    with open('cache/cache.pkl', 'wb') as f:\n",
        "        pickle.dump(cache, f)\n",
        "\n",
        "# Selecionar arquivo de áudio\n",
        "def selecionar_arquivos():\n",
        "    uploaded = files.upload()\n",
        "    arquivos_de_audio_uploadados = []\n",
        "    for arquivo_de_audio in uploaded.keys():\n",
        "        if arquivo_de_audio.endswith('.mp3') or arquivo_de_audio.endswith('.wav'):\n",
        "            arquivos_de_audio_uploadados.append(arquivo_de_audio)\n",
        "    print(\"Arquivos de áudio uploadados:\")\n",
        "    for i, arquivo in enumerate(arquivos_de_audio_uploadados):\n",
        "        print(f\"{i+1}. {arquivo}\")\n",
        "    return arquivos_de_audio_uploadados\n",
        "\n",
        "# Função para processar e salvar transcrição de um único arquivo de áudio\n",
        "def processar_audio(arquivo_de_audio):\n",
        "    if arquivo_de_audio in cache:\n",
        "        print(f\"Arquivo de áudio '{arquivo_de_audio}' já foi baixado e transcrito. Usando cache...\")\n",
        "        texto, duracao, total_palavras = cache[arquivo_de_audio]\n",
        "    else:\n",
        "        texto, duracao, total_palavras = transcrever_e_analisar_audio(arquivo_de_audio)\n",
        "        cache[arquivo_de_audio] = (texto, duracao, total_palavras)\n",
        "        salvar_cache(cache)\n",
        "\n",
        "    if texto:\n",
        "        texto_formatado = re.sub(r'([.!?])', r'\\1\\n', texto)\n",
        "\n",
        "        # Salvar a transcrição em um arquivo\n",
        "        nome_arquivo = arquivo_de_audio + '_transcricao.txt'\n",
        "        salvar_transcricao(texto_formatado, nome_arquivo)\n",
        "        print(f\"Transcrição salva em: {nome_arquivo}\")\n",
        "\n",
        "        # Retornar dados necessários para o CSV\n",
        "        return arquivo_de_audio.split('.')[0], texto, duracao, total_palavras\n",
        "    else:\n",
        "        print(f\"Erro ao transcrever o áudio {arquivo_de_audio}.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# Main\n",
        "cache = carregar_cache()\n",
        "arquivos_de_audio_uploadados = selecionar_arquivos()\n",
        "\n",
        "if arquivos_de_audio_uploadados:\n",
        "    resultados = []\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        for arquivo_de_audio in arquivos_de_audio_uploadados:\n",
        "            resultado = processar_audio(arquivo_de_audio)\n",
        "            if resultado[0]:  # Se houver transcrição\n",
        "                resultados.append(resultado)\n",
        "\n",
        "    # Criar DataFrame e salvar em CSV\n",
        "    df = pd.DataFrame(resultados, columns=['id_audio', 'transcricao', 'tempo_de_chamada', 'total_palavras'])\n",
        "    df.to_csv('transcricoes/transcricoes.csv', index=False)\n",
        "    print(\"CSV gerado com sucesso!\")\n",
        "else:\n",
        "    print(\"Erro ao carregar o arquivo de áudio.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l4wi4epoKn2",
        "outputId": "8f5bbbd3-c205-4d8c-f822-6acc60ec8cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rótulos adicionados e CSV atualizado!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "# Baixar recursos do NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Função para processar texto\n",
        "def processar_texto(texto):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'\\d+', '', texto)  # Remove números\n",
        "    palavras = texto.split()\n",
        "    palavras = [palavra for palavra in palavras if palavra not in stopwords.words('portuguese')]\n",
        "    palavras = [lemmatizer.lemmatize(palavra) for palavra in palavras]\n",
        "    return ' '.join(palavras)\n",
        "\n",
        "# Função para rotular automaticamente com base nas palavras-chave\n",
        "def rotular_transcricao(texto, limiar_promotor=1, limiar_detrator=1):\n",
        "    contagem_promotor = contar_palavras(texto, palavras_promotor)\n",
        "    contagem_detrator = contar_palavras(texto, palavras_detrator)\n",
        "    total_promotor = sum(contagem_promotor.values())\n",
        "    total_detrator = sum(contagem_detrator.values())\n",
        "\n",
        "    if total_promotor >= limiar_promotor and total_promotor > total_detrator:\n",
        "        return \"promotor\"\n",
        "    elif total_detrator >= limiar_detrator and total_detrator > total_promotor:\n",
        "        return \"detrator\"\n",
        "    else:\n",
        "        return \"neutro\"\n",
        "\n",
        "# Função para contar palavras de destaque\n",
        "def contar_palavras(texto, palavras):\n",
        "    contagem = {palavra: texto.lower().count(palavra) for palavra in palavras}\n",
        "    return contagem\n",
        "\n",
        "# Função para realizar a rotulagem\n",
        "def realizar_rotulagem(diretorio):\n",
        "    df = pd.read_csv(os.path.join(diretorio, 'transcricoes.csv'))\n",
        "    rotulos = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        texto_processado = processar_texto(row['transcricao'])\n",
        "        rotulo = rotular_transcricao(texto_processado)\n",
        "        rotulos.append(rotulo)\n",
        "\n",
        "    # Adicionar rótulos ao DataFrame e salvar em CSV\n",
        "    df['rotulo'] = rotulos\n",
        "    df.to_csv(os.path.join(diretorio, 'transcricoes_rotuladas.csv'), index=False)\n",
        "    print(\"\\nRótulos adicionados e CSV atualizado!\")\n",
        "\n",
        "# Definir palavras de destaque para promotores e detratores\n",
        "palavras_promotor = [\n",
        "    \"ótimo\", \"excelente\", \"muito bom\", \"bom\", \"satisfeito\", \"recomendo\",\n",
        "    \"gostei\", \"amor\", \"paixão\", \"orgulho\", \"satisfação\", \"facilidade\", \"eficiência\",\n",
        "    \"boa experiência\", \"produto incrível\", \"suporte excelente\"\n",
        "]\n",
        "palavras_detrator = [\n",
        "    \"ruim\", \"péssimo\", \"muito ruim\", \"desapontado\", \"insatisfeito\", \"não recomendo\",\n",
        "    \"não gostei\", \"ódio\", \"desgosto\", \"desapontamento\", \"descontentamento\",\n",
        "    \"dificuldade\", \"inconveniente\", \"problema\", \"erro\", \"falta de suporte\"\n",
        "]\n",
        "\n",
        "# Realizar a rotulagem\n",
        "realizar_rotulagem('transcricoes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "x8PG1ge3yVtb",
        "outputId": "3cf2f9ff-9ee3-4b02-cdfa-6da89df8889e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c54b4eb0-492a-41f8-aead-bd2ab17c6831\", \"concatenado.csv\", 28781)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "df = pd.read_csv('transcricoes/transcricoes_rotuladas.csv')\n",
        "df['tempo_de_chamada'] = df['tempo_de_chamada'].astype(int)\n",
        "\n",
        "\n",
        "# Salvar o DataFrame concatenado em um novo CSV com separador ';'\n",
        "df = df.to_csv('transcricoes/concatenado.csv', sep=';', index=False)\n",
        "\n",
        "# Baixar o arquivo concatenado\n",
        "files.download('transcricoes/concatenado.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kUSD7tSoAPwN",
        "outputId": "ea239739-d112-4450-cfe0-177f25718b83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id_audio                                        transcricao  \\\n",
              "0   2874774  <p>Candinavia, Natalia, bom dia. Bom dia, Nata...   \n",
              "1   2874830  <p>Bom dia, eu falo com o Sr. Pedro. Bom dia, ...   \n",
              "2   2961972  <p>Alô, bom dia. Alô, bom dia. Alô? Alô, bom d...   \n",
              "3   2962046  <p>Depende de Cláudia. Oi Cláudia, bom dia. Lí...   \n",
              "4   2962074  <p>Alô, Alô. Fala com o Sr. Pedro Rogério. Iss...   \n",
              "\n",
              "   tempo_de_chamada  total_palavras    rotulo  \n",
              "0               301             627  promotor  \n",
              "1               354             827  promotor  \n",
              "2               563            1486  promotor  \n",
              "3               177             401  detrator  \n",
              "4               661            1605  detrator  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed56ede6-18e1-44e3-9391-7027131300eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_audio</th>\n",
              "      <th>transcricao</th>\n",
              "      <th>tempo_de_chamada</th>\n",
              "      <th>total_palavras</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2874774</td>\n",
              "      <td>&lt;p&gt;Candinavia, Natalia, bom dia. Bom dia, Nata...</td>\n",
              "      <td>301</td>\n",
              "      <td>627</td>\n",
              "      <td>promotor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2874830</td>\n",
              "      <td>&lt;p&gt;Bom dia, eu falo com o Sr. Pedro. Bom dia, ...</td>\n",
              "      <td>354</td>\n",
              "      <td>827</td>\n",
              "      <td>promotor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2961972</td>\n",
              "      <td>&lt;p&gt;Alô, bom dia. Alô, bom dia. Alô? Alô, bom d...</td>\n",
              "      <td>563</td>\n",
              "      <td>1486</td>\n",
              "      <td>promotor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2962046</td>\n",
              "      <td>&lt;p&gt;Depende de Cláudia. Oi Cláudia, bom dia. Lí...</td>\n",
              "      <td>177</td>\n",
              "      <td>401</td>\n",
              "      <td>detrator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2962074</td>\n",
              "      <td>&lt;p&gt;Alô, Alô. Fala com o Sr. Pedro Rogério. Iss...</td>\n",
              "      <td>661</td>\n",
              "      <td>1605</td>\n",
              "      <td>detrator</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed56ede6-18e1-44e3-9391-7027131300eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed56ede6-18e1-44e3-9391-7027131300eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed56ede6-18e1-44e3-9391-7027131300eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bed5fe15-8f44-44ac-baed-729713608c56\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bed5fe15-8f44-44ac-baed-729713608c56')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bed5fe15-8f44-44ac-baed-729713608c56 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id_audio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47777,\n        \"min\": 2874774,\n        \"max\": 2962074,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2874830,\n          2962074,\n          2961972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcricao\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<p>Bom dia, eu falo com o Sr. Pedro. Bom dia, sou eu mesmo. Sr. Pedro me chama Beatriz, falo da Tots, tudo bem? Da Tots? Isso. Tudo bem, Sr. Pedro? Que bom. O Sr. Seria o respons\\u00e1vel ainda pelo DP e utiliza o sistema na empresa complexo Brasil? Sim, o Sr. Seria pelo DP, \\u00e9 a Ana Carla. O Sr. Seria pelo RH? Porque para mim aqui est\\u00e1 como o DP, o senhor. Sim, sim. Mas o respons\\u00e1vel no DP e a Ana Carla. , entendi. O Sr. Seria respons\\u00e1vel ent\\u00e3o? N\\u00e3o, eu trabalho com o sistema, sim, ajudo, faz as foras de pagamento, mas a contenadora e a Ana Carla. , entendi. \\u00c9 que eu preciso fazer um acompanhamento com um respons\\u00e1vel para a gente saber como que est\\u00e1 a\\u00ed a experi\\u00eancia de voc\\u00eas. Ser\\u00e1 que ela tem dois minutinhos para falar comigo agora? \\u00c9 a Ana Carla, n\\u00e9? \\u00c9 a Ana Carla.  bom. Vou te assinar para ela, 47.06. Obrigada. O Sr. Seria o respons\\u00e1vel pela \\u00e1rea e utiliza o sistema a topos na empresa? Isso. O dom\\u00ednio do Bloco do Brasil, 21, n\\u00e9? . Meu contato \\u00e9 bem r\\u00e1pido, Sarah Ana. Eu preciso fazer um acompanhamento s\\u00f3 para saber como trazer as foras de pagamento. \\u00c9, a Ana Carla. O Sr. Seria o respons\\u00e1vel pela \\u00e1rea e o sistema a topos na empresa? Isso. O dom\\u00ednio do Bloco do Brasil, 21, n\\u00e9? . Eu preciso fazer um acompanhamento s\\u00f3 para saber como est\\u00e1 a\\u00ed a experi\\u00eancia e satisfa\\u00e7\\u00e3o de voc\\u00eas. Esse acompanhamento \\u00e9 feito pelo m\\u00e9todo de NPS. Ent\\u00e3o, Sarah, valia somente de 0 a 10 a marca tal. S\\u00e3o uns pontos espec\\u00edficos que eu preciso perguntar. Dura dois minutos.  bom? S\\u00f3 confirmando, ent\\u00e3o, o CNPJ \\u00e9 07, 354, 754, meu contato \\u00e9 9,9. Ent\\u00e3o, na verdade, \\u00e9 o do Bloco C? Isso. O do Bloco C do Brasil, 21, t\\u00e1? , porque aqui eu cuido com... Tem outros CNPJ, esse \\u00e9 um que eu n\\u00e3o mexo. , entendi, mas a Sarah utiliza o sistema. Utilizo. , n\\u00e3o tem problema, t\\u00e1 bom?  bom. O e-mail que eu tenho aqui s\\u00f3 para confirmar da \\u00e1rea \\u00e9 o dpbr, Arroba Complexo Brasil, 21.com.br. Seria a Senhora tamb\\u00e9m? N\\u00e3o. Oh, seria da Senhora? N\\u00e3o. Arroba Melhia. , entendi, ent\\u00e3o vou deixar esses aqui. Eu tenho os dois a\\u00ed, eu atualizo como assim. Obrigada pela atualiza\\u00e7\\u00e3o. Nome, escala 0 a 10, ser\\u00e1 a probabilidade da Sarah recomendar a Totus, um amigo, um colega, hoje? \\u00c9 isso. Tem algum coment\\u00e1rio que a Sarah gostaria de deixar sobre a nota? N\\u00e3o, o sistema \\u00e9 muito completo, muito bom, eu gosto dele. O sistema \\u00e9 muito completo, t\\u00e1? O sistema \\u00e9 muito completo, t\\u00e1? O sistema \\u00e9 muito completo, t\\u00e1? O sistema \\u00e9 muito completo, t\\u00e1? O sistema \\u00e9 muito completo, t\\u00e1? Algo mais? N\\u00e3o. , para a gente aprofundar um pouquinho mais da melhoria, agora eu vou falar alguns pontos espec\\u00edficos e parece que a Sarah vai tamb\\u00e9m somente 0 a 10 caso ter encontrado, se n\\u00e3o tiver, n\\u00e3o precisa avaliar, t\\u00e1 bom? Falando do suporte t\\u00e9cnico, como a Sarah vai ler agilidade quando voc\\u00eas precisam de um atendimento do suporte. Desculpa, o que eu n\\u00e3o... Beatriz. Beatriz, seis. Seis, t\\u00e1. E o atendimento do agente do suporte, os analistas em geral que lhe d\\u00e1 com voc\\u00eas. A gente tem uma pessoa espec\\u00edfica aqui s\\u00f3, n\\u00e9? Eu continuo no seis. \\u00c9 dif\\u00edcil, n\\u00e3o \\u00e9 contato.  bom. Falando em rela\\u00e7\\u00e3o ao atendimento do comercial referente ao executivo de vendas, n\\u00e9? Esse eu n\\u00e3o tenho contato. N\\u00e3o, tudo bem. Custa e valor dos produtos contratados. A Sarah tem que ver o que a Sarah tem que ver. Os produtos contratados. A Sarah tem contato. Atendimento da administra\\u00e7\\u00e3o de um financeiro referente a boletos e negocia\\u00e7\\u00f5es caso precisem. Tamb\\u00e9m no meixo. Satisfa\\u00e7\\u00e3o com a implanta\\u00e7\\u00e3o do software? A Sarah estava quando o sistema foi implantado? N\\u00e3o, estava n\\u00e3o. Hoje o sistema entrega o benef\\u00edcio que voc\\u00eas precisam, entrega totalmente, parcialmente ou n\\u00e3o entrega? Entrega totalmente. . Como foi a experi\\u00eancia da senhora com a atualiza\\u00e7\\u00e3o do software? Voc\\u00eas j\\u00e1 atualizaram? Ser\\u00e1 que a Sarah como os horas final sente alguma diferen\\u00e7a? N\\u00e3o. N\\u00e3o. N\\u00e3o, a atualiza\\u00e7\\u00e3o n\\u00e3o \\u00e9 a gente que faz aqui. Mas a Sarah como os horas final? A Sarah tem ci\\u00eancia que foi atualizada? Sim, sim. Ent\\u00e3o a Sarah consegue avaliar? Zero a zero? Sim. 9? 9, t\\u00e1. Para finalizar a peste que a Sarah valia de 0 a 10 atendimento realizada pela TOTUS Unidade de Bras\\u00edlia \\u00e9 respons\\u00e1vel a\\u00ed por voc\\u00eas. O atendimento deles. Sete. S\\u00f3 essas as perguntas, ser\\u00e1 at\\u00e9 algum coment\\u00e1rio final? N\\u00e3o, n\\u00e3o.  bom, esse acompanhamento ele ocorre a cada 6 meses, t\\u00e1? Passando o per\\u00edodo, returnamos o contato. N\\u00e3o, n\\u00e3o, n\\u00e3o, n\\u00e3o, n\\u00e3o. Obrigada. Teria alguma empresa que gostaria de indicar para a gente? N\\u00e3o, momento n\\u00e3o. N\\u00e3o, n\\u00e3o, n\\u00e3o, n\\u00e3o. Tudo bem, ent\\u00e3o, eu agrade\\u00e7o que a Sarah tenha um \\u00f3timo dia e bom trabalho, Sarah. Obrigada.</p>\",\n          \"<p>Al\\u00f4, Al\\u00f4. Fala com o Sr. Pedro Rog\\u00e9rio. Isso. Sr. Pedro, me chamo Beatriz, falo da Toto, tudo bem? Oi Beatriz, tudo bem. Que bom. Sr. Pedro, voc\\u00ea seria ainda respons\\u00e1vel pelo sistema na Nucleu Y participa\\u00e7\\u00f5es da LTEA? Sim, sou eu, sou eu, sou eu. Sr. Pedro, bem r\\u00e1pido meu contato, t\\u00e1? Eu falo da parte da experi\\u00eancia do cliente e eu gostaria de saber de como est\\u00e1 a percep\\u00e7\\u00e3o, acompanhar um pouquinho a experi\\u00eancia. P\\u00e9ssimo. Entendi, Sr. Pedro, esse acompanhamento... J\\u00e1 fiz v\\u00e1rias vezes essa pesquisa, esse ano eu tive muito problema. Pode colocar a menor nota em todos os aspectos, atendimento, transformamento, cloud, vis\\u00e3o. A \\u00fanica coisa que \\u00e9 bem feita \\u00e9 a pesquisa, essa voc\\u00ea pode forpar nota boa. Entendi. Eu preciso formalizar, t\\u00e1, Sr. Pedro? Claro, vamos l\\u00e1. ? S\\u00f3 confirmando ent\\u00e3o, voc\\u00ea limpe j\\u00e1 at\\u00e9 o 21, 183, 718, me contra 30, t\\u00e1? Muito mesmo. O e-mail do Sr. Continua Pedro.Sampaia, rouba central... \\u00d3, esse, ponto como? Ponto para. Isso, obrigada pela confirma\\u00e7\\u00e3o. Sr. Pedro, ent\\u00e3o, iniciando no Miscala 010, qual a probabilidade do Sr. recomendar a TOTO? Zero. , tem algum coment\\u00e1rio aqui que voc\\u00ea vai deixar? Qual \\u00e9 o seu... A TOTO tem o p\\u00e9ssimo relacionamento com o cliente. Ela n\\u00e3o entende o cliente, ela n\\u00e3o atende bem o cliente. Ela tem um comercial muito bom, ela vende muito bem, mas ap\\u00f3s o contrato dela \\u00e9 horr\\u00edvel, \\u00e9 p\\u00e9ssimo. A empresa n\\u00e3o entende que existem clientes de menor porte, n\\u00e3o entende como funciona as estruturas dos seus clientes. Ela trata como se fosse um produto... Ela vende um produto que n\\u00e3o \\u00e9 de prateleira, mas por\\u00e9m ela tem um produto de prateleira. N\\u00e3o tem clientes de menor porte, n\\u00e9? A menor porte \\u00e9 uma empresa que aprecia 60 milh\\u00f5es por ano, nem t\\u00e3o menor assim, n\\u00e9? Eu fico imaginando col\\u00e9gios menores, col\\u00e9gios que tem estruturas menores... Al\\u00f4? N\\u00e3o, eu fico em nossa... Al\\u00f4? A nossa grupo at\\u00e9 \\u00e9 razoavelmente grande, ent\\u00e3o, faturamente, 60, 70 milh\\u00f5es por ano. Eu fico imaginando, eu fico imaginando n\\u00e3o, porque eu at\\u00e9 conhe\\u00e7o col\\u00e9gios menores que tem um TOTO. At\\u00e9 uma vergonha, os caras n\\u00e3o conseguem trabalhar com isso. O Cloudp\\u00e9ssimo, a estrutura da Cloudp\\u00e9ssima, o time de Cloudp\\u00e9ssimo, ele \\u00e9 muito fraco, n\\u00e3o tem conhecimento t\\u00e9cnico, n\\u00e3o ouve o cliente, n\\u00e3o fala com o cliente. Eu j\\u00e1 tive problema de prensa de dados, eu j\\u00e1 tive que \\u00e9 desse sistema aqui que demorou horas pra morfar. J\\u00e1 abri chamado pra solu\\u00e7\\u00f5es simples, que se transformaram em extremamente complexas. Todos os meus chamados, eu tenho que abrir um chamado no Cloud e tem que abrir um chamado na vidoria, porque esse n\\u00e3o \\u00e9 atendido de forma correta. Principalmente, o n\\u00edvel t\\u00e9cnico \\u00e9 muito baixo, \\u00e9 muito baixo, \\u00e9 muito fraco. Vamos ver se \\u00e9 o primeiro n\\u00edvel, talvez \\u00e9 porque a gente se relaciona sempre no primeiro n\\u00edvel, mas \\u00e9 muito baixo. N\\u00e3o, n\\u00e3o \\u00e9 atendido. O NDE \\u00e9 educacional financeiro completo. RH \\u00e9 pouqu\\u00edssima coisa, alguma coisa ou outra. Mas no modo geral \\u00e9 isso, educacional financeiro. O RH \\u00e9 educacional, n\\u00e3o \\u00e9? Eu acho que o maior ponto \\u00e9 a quest\\u00e3o de relacionamento. A TOTA tem um p\\u00e9ssimo relacionamento com o cliente, p\\u00f3s-contratos, os ARs da TOTAS, todos os centros s\\u00e3o p\\u00e9ssimos, as empresas fazem o relacionamento, que v\\u00eam de centros, as quest\\u00f5es de consultoria, a TOTAS tem que ser mais clara nas indica\\u00e7\\u00f5es. A gente tem que ter uma responsabilidade com a consultoria homologada, ela n\\u00e3o tem. A gente tem que ficar sempre a merc\\u00ea de m\\u00e3o de obra, nem sempre t\\u00e3o bem qualificada, t\\u00e3o bem n\\u00e3o treinada, e a TOTAS n\\u00e3o consegue tamb\\u00e9m fornecer esse tipo de coisa. Porque, veja, eu tenho consultoria que trabalha comigo, a\\u00ed eu falo assim, n\\u00e3o, a consultoria est\\u00e1 me dando problema. Eu vou l\\u00e1 na TOTAS e falo, TOTAS, preciso de consultoria para resolver um problema. A\\u00ed a TOTAS vai l\\u00e1 e me manda um t\\u00e9cnico aqui que ele j\\u00e1 v\\u00ea aqui por outra consultoria. J\\u00e1 aconteceu um n\\u00famero \\u00e0s vezes aqui, chega a ser at\\u00e9, e ainda me cobra tr\\u00eas vezes mais que a consultoria est\\u00e1 me cobrando aqui. E manda o mesmo t\\u00e9cnico assim, j\\u00e1 tive casos do cara chegar e eu vou falar, n\\u00e3o, pode voltar. Eu estou contratando a consultoria porque voc\\u00ea n\\u00e3o resolveu e a TOTAS mandou voc\\u00ea para l\\u00e1. Com consultoria que eu falei que resolveu? Esse conceito de terceriza\\u00e7\\u00e3o da TOTAS que ela faz de parceria com a consultoria, como o mercado \\u00e9 muito pequeno, eu estou falando do mundo educacional, isso aqui \\u00e9 R&amp;M, o Proteus \\u00e9 outra hist\\u00f3ria, outros modos s\\u00e3o outra hist\\u00f3ria. Como o mercado \\u00e9 muito pequeno, voc\\u00ea cai no meu lugar. Acho que \\u00e9 pra isso, acho que \\u00e9 s\\u00f3 isso.  bom.  bom. Algo mais? Zero. Eles s\\u00e3o simp\\u00e1ticos, eles s\\u00e3o educados, isso \\u00e9 decente que est\\u00e3o. Ent\\u00e3o, foi cinco. E \\u00e9 um faro contra os espec\\u00edficos e parece que o senhor Avali tamb\\u00e9m somente zero a 10, 4, t\\u00e1? Zero. Sala de parte t\\u00e9cnico, como o senhor Avali a agilidade nos processos do super. Pensando em mercado, ele n\\u00e3o \\u00e9 um produto caro pensando na parte de m\\u00e3o de obra pra isso, mas em produtos, sim. \\u00c9 mais. O que \\u00e9 o valor dos produtos usados? Zero. Entendi, esse eu precisava ir antes do zero, esse. A nossa implota\\u00e7\\u00e3o, ela \\u00e9 mais complexa, a\\u00ed eu tamb\\u00e9m n\\u00e3o posso, posso, que n\\u00e3o sei o que fez, teve imigra\\u00e7\\u00f5es, etc. Eu vou deixar cinco. Entendi, t\\u00e1. Satisfa\\u00e7\\u00e3o com a implanta\\u00e7\\u00e3o do software? Parcialmente.  falando de funcionalidade, de recursos, n\\u00e9? Hoje \\u00e9 um sistema, ele entrega o benef\\u00edcio que a empresa precisa, entrega totalmente, parcialmente ou n\\u00e3o entrega? \\u00c9, t\\u00e1 vendo um ter\\u00e1zo, cinco. A atualiza\\u00e7\\u00e3o do software, zero test tamb\\u00e9m, caso tenha fun... Zero. As atualiza\\u00e7\\u00f5es, n\\u00e9, de uma forma em geral, a experi\\u00eancia? Tenho, o total precisa melhorar o relacionamento urgente com o cliente. A gente s\\u00f3 n\\u00e3o sai do... A gente faz parte de um grupo de escolas de estado de S\\u00e3o Paulo, n\\u00e9? A Bepar, \\u00e9 o maior grupo de escolas privadas de estado de S\\u00e3o Paulo. A gente tem oitenta escolas. A gente s\\u00f3 n\\u00e3o sai do salto de op\\u00e7\\u00e3o. Se a TOTUS n\\u00e3o dia apareceu um sistema que tem o que o TOTUS tem, o TOTUS vai ter 30% de clientes em S\\u00e3o Paulo. Por falta de op\\u00e7\\u00e3o. N\\u00e3o tem op\\u00e7\\u00e3o no mercado. Ent\\u00e3o, assim, a TOTUS ela ganha porque ela tem o monop\\u00f3lio do mercado, n\\u00e3o \\u00e9 porque ela \\u00e9 boa. Ainda n\\u00e3o \\u00e9 uma escolha vi\\u00e1vel, ela \\u00e9 uma escolha de falta de op\\u00e7\\u00e3o. Entendeu? Porque a maioria das empresas vem de sistema educacional, mas eles n\\u00e3o t\\u00eam financeiro. A\\u00ed outras v\\u00eam de financeiro, mas a\\u00ed n\\u00e3o tem educa\\u00e7\\u00e3o legal. Outras v\\u00eam de app, e a\\u00ed o app n\\u00e3o tem financeiro, n\\u00e3o tem educa\\u00e7\\u00e3o legal. Ent\\u00e3o, a TOTUS \\u00e9 a \\u00fanica que consegue ter alguma coisa mais ou menos de todas as \\u00e1reas. Entendi. Eu acho que... Eu respondi pra treino, eu tava de f\\u00e9rias a \\u00faltima vez. Eu sa\\u00ed no final do ano de f\\u00e9rias, ent\\u00e3o foi tr\\u00eas meses que eu respondi. . Esse acompanhamento, o senhor Pedro, ele ocorre nos tr\\u00eas meses, na um ano. Passando o per\\u00edodo, vamos retornar o contato. Por\\u00e9m...  bom. A gente... Oi? O que voc\\u00ea falou? , porque esse fato agora... Eu tenho centenas. Eu passo de dez, eu chamo a Agus de Vitoria, e meio, me escalando. Reclama\\u00e7\\u00f5es direto para diretores de alto n\\u00edvel no Ikea-v, voc\\u00eas. Eu reclamo de todas as formas que eu posso. Eu j\\u00e1 falei que todos os n\\u00edveis que voc\\u00ea pode imaginar. E parece que eu acho que... A\\u00ed tamb\\u00e9m tem um lado que eu sei, o artido, a gente n\\u00e3o tem muita sorte. Acontece coisas comigo aqui no Clio Y, que n\\u00e3o \\u00e9 muito comum ocorrer tamb\\u00e9m. Eu n\\u00e3o sei se \\u00e9 de tanto reclamar que acabou criando mais animizar. N\\u00e3o sei o que ocorre, mas ocorre coisas que \\u00e9 bem complexas. Eu acho que todos os analistas de S\\u00e3o Paulo conhecem o Clio Y, quando ligar, porque sempre que ligue, \\u00e9 muita reclama\\u00e7\\u00e3o. Eu j\\u00e1 ligo reclamando, porque o n\\u00edvel de aconvimento \\u00e9 muito ruim. \\u00c9 muito ruim mesmo, assim. Se eu tenho um problema de portal, eu preciso de um problema de portal. J\\u00e1 aconteceu de ligar, se um problema de portal, vou dar um exemplo. Eu sei que voc\\u00eas s\\u00e3o mais da parte comercial, pesquisa, etc. Mas imagina, tem um portal do aluno, onde para entrar l\\u00e1, ver na alta dos filhos, boletas. E tem um problema l\\u00e1. Eu abro um chamado para resolver. Eles foram l\\u00e1 e colocaram a base de testes na minha base de produ\\u00e7\\u00e3o, do atualizado de fevereiro. Faz sentido algumas coisas desse tipo, assim, e n\\u00e3o faz. Isso ocorreu, foi o \\u00faltimo caso que eu tive que voc\\u00eas ocorreram duas semanas. Voc\\u00ea imagina, eu abri um chamado, porque um portal saiu do ar. Um problema, provavelmente de S, de servidor, alguma coisa assim. Simplesmente, entrou cara a base. Meu sistema reinicia, quando volta, ele volta a acabar com a base de fevereiro. E a base de atualizado era a base de testes. Voc\\u00ea entendeu? Olha o n\\u00edvel que eu estou, assim. Quando eu falo baixa, porque esse tipo de coisa, eu concordo com isso.  bom? Imagina aqui, eu tamb\\u00e9m agrade\\u00e7o. Obrigada por qualquer coisa. Igualmente, at\\u00e9 mais. Entendi, S\\u00e9rgio Pedro. Ok, aos pontos f\\u00f3sicos, voc\\u00ea me trouxe. Passando o per\\u00edodo, ent\\u00e3o, retornaremos o contato. Eu agrade\\u00e7o, t\\u00e1 bom? Espero que isso...  bom, \\u00e9 um \\u00f3timo dia. Tchau, tchau.</p>\",\n          \"<p>Al\\u00f4, bom dia. Al\\u00f4, bom dia. Al\\u00f4? Al\\u00f4, bom dia. Falo que o senhor Diogo tem cheira. Isso. O senhor Diogo me chama Beatriz, falo da TOPS, tudo bem? Tudo bem, Beatriz, eu vou fazer uma coisa. Estou bem, obrigado. O senhor est\\u00e1 me ouvindo bem agora? Estou bem. . O senhor Diogo, o meu contato \\u00e9 bem r\\u00e1pido e simples. O senhor seria ainda ressens\\u00e1vel pelo tema na empresa, na polic\\u00f4nso e por empresarial? Sim. Eu falo da parte da experi\\u00eancia do cliente, o senhor Diogo, e eu preciso fazer um acompanhamento para saber como que est\\u00e1 a\\u00ed a percep\\u00e7\\u00e3o de voc\\u00eas. \\u00c9 bem r\\u00e1pido e simples, por\\u00e9m importante para a gente entender a experi\\u00eancia que est\\u00e3o tendo, t\\u00e1? Esse acompanhamento ele \\u00e9 feito pelo m\\u00e9todo de NPS, ent\\u00e3o o senhor avalia somente 0,10, a TOPS, \\u00e9 uns pontos espec\\u00edficos, dura dois minutinhos, t\\u00e1 bom?  bom, t\\u00e1. Eu vou confirmando o s\\u00eanin para a jota da empresa, o 11, 319, 7,6, 9, 1,9, 3, ok? Isso. O e-mail do senhor continua Diogo, ponto-teixeira, rouba na policonsocatoria, ponto-com, ponto-br. Isso mesmo. Obrigada pela confirma\\u00e7\\u00e3o. Ent\\u00e3o, iniciando numa escala de Zara Bessard, o senhor recomendar\\u00e1 a TOPS ao amigo ou colega hoje, na vis\\u00e3o, o senhor tem? Nove. Tem algum coment\\u00e1rio que gostaria de deixar sobre a nota? N\\u00e3o, n\\u00e3o, bom sistema, tem de toda legisla\\u00e7\\u00e3o. S\\u00f3 tem que agir de surpresa nesse neg\\u00f3cio dos novos releases, n\\u00e9? Que tem que todo mundo ir pro banco. Entendi. Vai ter que mexer em todas as quest\\u00f5es de a\\u00e7\\u00f5es, entendeu? Ent\\u00e3o t\\u00e1 bom, para a gente abra\\u00e7ar um pouquinho mais na melhoria, agora vou suar alguns pontos espec\\u00edficos e pe\\u00e7o que o senhor avalia tamb\\u00e9m somente 0,10, caso tenha contato, t\\u00e1? Falando do suporte t\\u00e9cnico, como o senhor avalia agilidade nos processos do suporte t\\u00e9cnico? Muito bom. N\\u00e3o teve problema n\\u00e3o com suporte t\\u00e9cnico, sendo que eu liga e eles resolvem. am. Dentro do prazo. De Zara Bessard, t\\u00e1? Do SNA, n\\u00e9? 10. . Falando em rela\\u00e7\\u00e3o ao atendimento dos agentes do suporte, n\\u00e9? Como que o senhor avalia o atendimento dos agentes? Sim, tamb\\u00e9m, s\\u00e3o muito bons. Bem qualificados. , falando em rela\\u00e7\\u00e3o ao comercial, o atendimento do executivo de vendas de voc\\u00eas. am. Bom, ela atendia bem. A\\u00ed ultimamente eu mando e-mail mensagem, ela n\\u00e3o responde mais n\\u00e3o. Entendi, ent\\u00e3o o senhor n\\u00e3o tem mais contato? N\\u00e3o, eu at\\u00e9 tenho contato dela, mas eu mando, por exemplo, que nem recentemente ela me mandou sobre licen\\u00e7as, n\\u00e9? Que tava, por exemplo, a gente tem 5 licen\\u00e7as, excedeu, tipo uma pessoa que devia fazer um trabalho tempor\\u00e1rio na final de semana, acabou acessando junto com as outras pessoas, entendeu? E a\\u00ed eu mandei responde o e-mail dela, mandei mensagem no WhatsApp, s\\u00f3 que eu n\\u00e3o tive resposta dela n\\u00e3o. Ent\\u00e3o eu n\\u00e3o sei o que aconteceu, n\\u00e3o sei se ela mudou de celular, mas n\\u00e3o respondeu nem o e-mail, n\\u00e9? am. A\\u00ed eu n\\u00e3o tive resposta, t\\u00e1? Nessa \\u00faltima intera\\u00e7\\u00e3o que eu tive, ela n\\u00e3o me respondeu nem no WhatsApp, nem no e-mail. A\\u00ed eu n\\u00e3o sei o que pode ter acontecido. Entendi. Ent\\u00e3o o senhor avalia enquanto de 0 a 10? , vou dar um sete, ela sempre me atendeu bem, mas nesse \\u00faltimo intera\\u00e7\\u00e3o ela n\\u00e3o me atendeu n\\u00e3o.  bom. Em rela\\u00e7\\u00e3o aos custos e valores dos produtos contratados, como o senhor avalia de 0 a 10? , t\\u00e1 dentro da margem, assim, eu confidere. Entendeu? \\u00c9 que eu n\\u00e3o tenho muito experi\\u00eancia, assim, dentro de outros RP, n\\u00e9? Pra ser minha vida, eu s\\u00f3 deixo um processo. Ent\\u00e3o eu n\\u00e3o preciso dizer que o custo dele \\u00e9 mais elevado ou mais barato, entendeu? Mas assim, pelo que ele entrega e pelo valor que hoje a empresa paga, o custo dele \\u00e9 um bom custo dele aqui. Ent\\u00e3o o senhor avalia de 0 a 10 quanto? Vada, ali \\u00e9 um nove. . O atendimento do financeiro referente a boletos, negocia\\u00e7\\u00f5es, caso precisem, certem contato? Quando eu precisei me responder na obra, muito r\\u00e1pido, entendeu? Quando eu precisei ver o que est\\u00e1 assim, a fatura tipo o valor, n\\u00e9? Que foi uma corre\\u00e7\\u00e3o de GPM, n\\u00e9? Essas corre\\u00e7\\u00f5es que tem no valor e para me responder rapidamente. Ent\\u00e3o o que est\\u00e1 acontecendo? Pegue no nove. . A satisfa\\u00e7\\u00e3o com a implanta\\u00e7\\u00e3o do s\\u00f3sseiro? O senhor participou da implanta\\u00e7\\u00e3o? M\\u00f4, olha s\\u00f3, eu vou te falar a verdade. Quem implantou para essa empresa, N\\u00e1poli, foi a Totus e Bigapueca. Desde 2016, desde 2015, que eles come\\u00e7aram a ser implanta\\u00e7\\u00e3o, em 2018 n\\u00e3o tinha terminado. Eu fui contratado justamente para finalizar a terragia implanta\\u00e7\\u00e3o e p\\u00f5e a implanta\\u00e7\\u00e3o, entendeu? Eu n\\u00e3o precisei falar para mim o hist\\u00f3rico, assim, eu n\\u00e3o participei na implanta\\u00e7\\u00e3o, mas eu fui contratado justamente para terminar ela, porque a parte de Bigapueca n\\u00e3o conseguiu terminar, entendeu? Agora, os motivos, eu n\\u00e3o sei porque v\\u00e1rias pessoas sa\\u00edram, entendeu? Se estressaram com projetos, tal. Ent\\u00e3o eu n\\u00e3o sei se \\u00e9 culpa da mapa e tamb\\u00e9m culpa da Totus e Bigapueca, eu n\\u00e3o posso s\\u00f3 por culpa, porque tudo n\\u00e3o pode levar para o era. Sempre algu\\u00e9m vai contar, n\\u00e9, vantar a gente para voc\\u00ea, n\\u00e9, sempre vai p\\u00f4r a culpa da Totus e Bigapueca, o pessoal da N\\u00e1poli p\\u00f5e a culpa da Totus e Bigapueca, o pessoal da Posttifos e a Totus e Bigapueca, mas n\\u00e3o \\u00e9 a culpa da N\\u00e1poli, voc\\u00ea \\u00e9 bom, eu vou implantar e terminar de implantar isso. Ent\\u00e3o se voc\\u00ea perguntar para mim, eu daria um sete para Totus e Bigapueca, porque eu j\\u00e1 tive que ter conhecido outra empresa que eu trabalhei com a Totus e Bigapueca. Entendeu? Na verdade, quando ela nem quis chamar para a Bigapueca, ela s\\u00f3 quis a Bigapueca, ela implantou uma antiga empresa que eu trabalhava. , ent\\u00e3o hoje o sistema est\\u00e1 entregando o benef\\u00edcio que voc\\u00ea precisa, a entrega totalmente, parcialmente para a entrega? N\\u00e3o, eu entrego a entrega depois que eu implantei tudo. Eu implantei o Gini, todos os obriga\\u00e7\\u00f5es para esses carros e para a gente usar um modo, agora ele est\\u00e1 funcionando pernamente. Totalmente, n\\u00e9, est\\u00e1 bom. Como foi a experi\\u00eancia do senhor com a atualiza\\u00e7\\u00e3o do software? Zero desk tamb\\u00e9m? , para mim foi bem trepilo, viu? Bem trepilo. S\\u00f3 essa nova a\\u00ed, a utiliza\\u00e7\\u00e3o, esse novo release aqui, que vai me fazer ter que concretar o programa doog para poder ajustar tudo no sonte para funcionar com edicion\\u00e1rios no banco, n\\u00e9? Acho que a torcida deveria ter dado mais prazo para isso a\\u00ed, porque tem emprestos que tem muita customiza\\u00e7\\u00e3o, n\\u00e9? E a gente trabalha com programadores pontuais, ent\\u00e3o isso j\\u00e1 \\u00e9 um profundo alto pra empresa, que eu vou ter que contratar um programador para ajustar 256 customiza\\u00e7\\u00f5es que eu tenho na base, entendeu? E ele j\\u00e1 expira agora em junho. E como se arrava ali ent\\u00e3o a experi\\u00eancia com as atualiza\\u00e7\\u00f5es? N\\u00e3o, com as atualiza\\u00e7\\u00f5es passadas que n\\u00e3o tinha mudan\\u00e7a, eu daria 9, agora com essa nova vai ir para o assalto de tempo, daria 6, eu acho que seria que serve esse sonte. Ent\\u00e3o eu vou usar com mais tempo para fazer esse program\\u00e1rio. Mas, n\\u00e3o \\u00e9 que acontece, tem que seguir em frente, n\\u00e9? , ent\\u00e3o nota 6, isso? N\\u00e3o, eu vou dar 8 para atualizar s\\u00f3 isso. Eu daria a solu\\u00e7\\u00e3o essa nova, n\\u00e9? Mas como voc\\u00ea est\\u00e1 contando com algo que eu ainda n\\u00e3o fiz, n\\u00e9? Ent\\u00e3o voc\\u00ea ajusta em dar 6, \\u00e9 porque as outras que eu fiz, eu n\\u00e3o tenho que. , para finalizar ent\\u00e3o, Sr. Diogo, eu pe\\u00e7o que voc\\u00ea estava ali tamb\\u00e9m 010 atendimento realizado pela T\\u00f3xida Ibirapuera, a unidade respons\\u00e1vel a\\u00ed por voc\\u00eas. Olha, eu daria 7. S\\u00e3o essas as perguntas? Ser\\u00e1 que tem algum coment\\u00e1rio final, mas algum ponto? N\\u00e3o, n\\u00e3o, s\\u00f3 isso mesmo. N\\u00e3o? Teria alguma empresa que voc\\u00ea ia indicar para a gente? Algum empresa que eu ia indicar? Isso, para a gente oferecer nosso produto? , voc\\u00ea pode oferecer um IPO chamado Grand Torson. Como? Grand Torson, eles j\\u00e1 usavam para o teu, s\\u00f3 que a\\u00ed eles te deram problema, a\\u00ed agora eles formam um novo IPO de novo e est\\u00e3o usando outros sistemas. A\\u00ed talvez tenham oportunidade de voc\\u00eas. \\u00c9 Grand Torson? Isso, Grand Torson. Eles j\\u00e1 \\u00e9 um cliente de voc\\u00eas, viu? Se voc\\u00ea precisar isso, vai te chamar para. Grand Torson. \\u00c9, porque eles se desmancharam e agora voltaram de novo como Grand Torson, porque eles agagou a empresa, porque assim, a empresa de IPO, auditoria, consultoria, quando ela n\\u00e3o atende os requisitos da matriz fora, eles tiram o nome da empresa. Ent\\u00e3o ela te grantou, ent\\u00e3o voltou com HBL e agora voltou ao Grand Torson de novo, entendeu? Entendi.  bom, ent\\u00e3o eu coloco aqui. Muito obrigada, senhor Dior, o seu acompanhamento ocorre nos meses, h\\u00e1 um ano passando o per\\u00edodo, retornaremos contatos, t\\u00e1 bom? Tenha um \\u00f3timo trabalho, tchau. Obrigado.</p>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tempo_de_chamada\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 197,\n        \"min\": 177,\n        \"max\": 661,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          354,\n          661,\n          563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_palavras\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 531,\n        \"min\": 401,\n        \"max\": 1605,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          827,\n          1605,\n          1486\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rotulo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"detrator\",\n          \"promotor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df  = pd.read_csv('transcricoes/concatenado.csv', sep=';')\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}